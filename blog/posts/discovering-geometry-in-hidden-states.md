# Discovering Geometry in Hidden States

What can we learn by looking at how representations move through space during inference?

When a language model generates text, hidden states form trajectories—paths through representation space. These paths carry geometric signatures that reveal how the model's understanding evolves.

The hidden state isn't just a black box—it's a landscape with structure. By studying these paths, we can learn to read the model's internal "body language."
